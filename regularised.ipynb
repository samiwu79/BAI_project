{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c76d204",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "This experiment is implemented using PyTorch. The following cell verifies the PyTorch version and whether GPU acceleration is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3fc1afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e311e95",
   "metadata": {},
   "source": [
    "## Model 2: Regularised Deep Neural Network (DNN)\n",
    "\n",
    "To address the overfitting observed in the baseline model, we implement a regularised DNN architecture following the Cam-Ready paper design.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "- Input layer: number of neurons = number of input features  \n",
    "- Hidden Layer 1: 128 neurons  \n",
    "- Hidden Layer 2: 64 neurons  \n",
    "- Hidden Layer 3: 32 neurons  \n",
    "- Output layer: 1 neuron (predicting continuous power consumption)\n",
    "\n",
    "### Regularisation Techniques\n",
    "\n",
    "- ReLU activation\n",
    "- Batch Normalisation before activation\n",
    "- Dropout (p = 0.3) after each hidden layer\n",
    "- L2 weight decay (Î» = 0.01)\n",
    "- Adam optimizer\n",
    "- MSE loss function\n",
    "- Batch size = 64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4a0f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (4153, 3) (462, 3) (1154, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1) load data\n",
    "df = pd.read_csv(\"clean_ul_stage1.csv\")\n",
    "\n",
    "feature_cols = [\"airtime\", \"selected_mcs\", \"txgain\"]\n",
    "\n",
    "target_col = \"pm_power\"\n",
    "\n",
    "df = df.dropna(subset=feature_cols + [target_col]).copy()\n",
    "for c in feature_cols + [target_col]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df = df.dropna(subset=feature_cols + [target_col]).copy()\n",
    "df = df[df[target_col] > 0].copy() \n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values\n",
    "\n",
    "\n",
    "# 2) split: train/test then train/val\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val,  y_train, y_val  = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# 3) scale (fit ONLY on train)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "print(\"Shapes:\", X_train_s.shape, X_val_s.shape, X_test_s.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f960ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class RegularizedDNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegularizedDNN, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "X_train_tensor = torch.FloatTensor(X_train_s)\n",
    "X_test_tensor  = torch.FloatTensor(X_test_s)\n",
    "\n",
    "y_train_tensor = torch.FloatTensor(y_train).view(-1,1)\n",
    "y_test_tensor  = torch.FloatTensor(y_test).view(-1,1)\n",
    "\n",
    "input_dim = X_train_s.shape[1]\n",
    "\n",
    "model2 = RegularizedDNN(input_dim)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model2.parameters(),\n",
    "    lr=0.001,\n",
    "    weight_decay=0.01   # L2 regularisation\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4cfc684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UL dataset (model2) training:\n",
      "Epoch 001 | train MSE 105.024681 | val MSE 104.599503\n",
      "Epoch 010 | train MSE 0.633623 | val MSE 0.625232\n",
      "Epoch 020 | train MSE 0.393767 | val MSE 0.352687\n",
      "Epoch 030 | train MSE 0.234490 | val MSE 0.200634\n",
      "Epoch 040 | train MSE 0.248148 | val MSE 0.214999\n",
      "Epoch 050 | train MSE 0.227434 | val MSE 0.190935\n",
      "Epoch 060 | train MSE 0.326798 | val MSE 0.300932\n",
      "Epoch 070 | train MSE 0.249883 | val MSE 0.205872\n",
      "Epoch 080 | train MSE 0.190273 | val MSE 0.157135\n",
      "Epoch 090 | train MSE 0.234376 | val MSE 0.210683\n",
      "Epoch 100 | train MSE 0.197828 | val MSE 0.159149\n",
      "Epoch 110 | train MSE 0.176596 | val MSE 0.160130\n",
      "Epoch 120 | train MSE 0.183139 | val MSE 0.169760\n",
      "Epoch 130 | train MSE 0.147827 | val MSE 0.125393\n",
      "Epoch 140 | train MSE 0.168670 | val MSE 0.148724\n",
      "Epoch 150 | train MSE 0.146991 | val MSE 0.125951\n",
      "Epoch 160 | train MSE 0.125251 | val MSE 0.111948\n",
      "Epoch 170 | train MSE 0.117266 | val MSE 0.099210\n",
      "Epoch 180 | train MSE 0.111616 | val MSE 0.094849\n",
      "Epoch 190 | train MSE 0.116859 | val MSE 0.100610\n",
      "Epoch 200 | train MSE 0.118502 | val MSE 0.102444\n",
      "Best val MSE: 0.09196247905492783\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "# ---- add val tensors (no logic change, just for printing val MSE) ----\n",
    "X_val_tensor = torch.FloatTensor(X_val_s)\n",
    "y_val_tensor = torch.FloatTensor(y_val).view(-1, 1)\n",
    "\n",
    "best_val_mse = float(\"inf\")\n",
    "\n",
    "print(\"\\nUL dataset (model2) training:\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model2.train()\n",
    "    permutation = torch.randperm(X_train_tensor.size(0))\n",
    "\n",
    "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x = X_train_tensor[indices]\n",
    "        batch_y = y_train_tensor[indices]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model2(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # ---- epoch-end evaluation: train MSE & val MSE (like model1) ----\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        train_pred = model2(X_train_tensor)\n",
    "        val_pred   = model2(X_val_tensor)\n",
    "\n",
    "        train_mse = criterion(train_pred, y_train_tensor).item()\n",
    "        val_mse   = criterion(val_pred, y_val_tensor).item()\n",
    "\n",
    "    if val_mse < best_val_mse:\n",
    "        best_val_mse = val_mse\n",
    "\n",
    "    # print at the same rhythm as your model1 screenshot (every 10 epochs + epoch 1)\n",
    "    if (epoch == 0) or ((epoch + 1) % 10 == 0):\n",
    "        print(f\"Epoch {epoch+1:03d} | train MSE {train_mse:.6f} | val MSE {val_mse:.6f}\")\n",
    "\n",
    "print(f\"Best val MSE: {best_val_mse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cb5f9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model 2: Regularised DNN ===\n",
      "X: ['airtime', 'selected_mcs', 'txgain']  y: pm_power\n",
      "MSE  : 0.122160\n",
      "RMSE : 0.349514\n",
      "MAE  : 0.253338\n",
      "MRE% : 2.1707\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model2(X_test_tensor)\n",
    "\n",
    "y_pred = y_pred.numpy().flatten()\n",
    "y_true = y_test_tensor.numpy().flatten()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def mean_relative_error(y_true, y_pred, eps=1e-9):\n",
    "    return np.mean(np.abs(y_true - y_pred) / (np.abs(y_true) + eps)) * 100\n",
    "\n",
    "mse  = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae  = mean_absolute_error(y_true, y_pred)\n",
    "mre  = mean_relative_error(y_true, y_pred)\n",
    "\n",
    "print(\"\\n=== Model 2: Regularised DNN ===\")\n",
    "print(\"X:\", feature_cols, \" y:\", target_col)\n",
    "print(f\"MSE  : {mse:.6f}\")\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n",
    "print(f\"MRE% : {mre:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oran311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
